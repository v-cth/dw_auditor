# ============================================================================
# Data Warehouse Audit Configuration
# ============================================================================
# This YAML file configures the table auditor behavior, including database
# connections, sampling, security settings, and output formats.

# Database Connection
# ----------------------------------------------------------------------------
database:
  # Database backend: 'bigquery' or 'snowflake'
  backend: "bigquery"

  # Connection parameters (backend-specific)
  connection_params:
    # For BigQuery:
    project_id: "portfolio-402"
    dataset_id: "dbt_prod"
    #credentials_path: "/path/to/service-account-key.json"
    # Or use credentials_json for JSON string/dict

    # For Snowflake (comment out BigQuery params and uncomment these):
    # account: "my-account"
    # user: "my-user"
    # password: "my-password"
    # database: "my_database"
    # warehouse: "my_warehouse"
    # role: "my_role"  # optional

  # Optional: Schema name (overrides connection default)
  # For BigQuery, this would be the dataset
  # For Snowflake, this would be the schema
  schema: null

# Tables to Audit
# ----------------------------------------------------------------------------
# Can be a simple list of table names OR objects with custom queries and primary keys
tables:
  # Simple table names
  - name: fct_avaibility
  - name: dim_station
    primary_key: station_code  # Optional: specify primary key column(s)
  - name: dtm_station_distance

  # Table with custom query (for filtering or joining)
  # - name: custom_table
  #   query: "SELECT * FROM my_table WHERE date > '2024-01-01'"
  #   primary_key: id


# Column-Level Check Configuration Matrix
# ----------------------------------------------------------------------------
# Configure which checks to run on which columns
column_checks:
  # Global defaults per data type
  defaults:
    string:
      trailing_spaces: true
      case_duplicates: true
      special_chars: true
      numeric_strings: true
    datetime:
      timestamp_patterns: true
      date_outliers: true

  # Per-table, per-column overrides
  tables:
    dim_station:
      # Skip special chars check for city column (we expect French accents)
      city:
        special_chars: false
      # Skip case duplicates and special chars for station_name (expected variation & French accents)
      station_name:
        case_duplicates: false
        special_chars: false  # Skip - French accents are expected

# Column Insights Configuration
# ----------------------------------------------------------------------------
# Configure data profiling insights (separate from quality checks)
column_insights:
  # Global defaults per data type
  defaults:
    string:
      # Show top N most frequent values with counts and percentages
      top_values: 10
      # String length statistics
      min_length: true
      max_length: true
      avg_length: true

    numeric:
      # Basic statistics
      min: true
      max: true
      mean: true
      median: true
      std: false  # Standard deviation (can be noisy)
      # Percentile breakdowns
      quantiles: [0.25, 0.5, 0.75]
      # Show top N most frequent values
      top_values: 5

    datetime:
      # Date range information
      min_date: true
      max_date: true
      date_range_days: true
      # Timezone info (for timezone-aware columns)
      most_common_timezones: 1
      # Most common dates with counts
      most_common_dates: 5
      # Most common days of week
      most_common_days: 7
      # Most common hours (0-23)
      most_common_hours: 10

  # Per-table, per-column overrides
  tables:
    dim_station:
      # Get detailed distribution for capacity column
      capacity:
        top_values: 5
        quantiles: [0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.99]
      # Minimal insights for station_code (primary key)
      station_code:
        top_values: 0  # Disable - primary key

    fct_avaibility:
      # Detailed date analysis for timestamp columns
      last_reported:
        most_common_dates: 3

# Sampling Configuration
# ----------------------------------------------------------------------------
sampling:
  # Number of rows to sample if table exceeds threshold
  sample_size: 10000
  
  # Row count threshold to trigger sampling
  sample_threshold: 10000
  
  # Use database-native sampling (faster, more secure)
  # If true, sampling happens in the database before loading data
  sample_in_db: true

# Security Settings
# ----------------------------------------------------------------------------
security:
  # Automatically mask columns containing PII
  mask_pii: true
  
  # Additional keywords to identify PII columns (beyond defaults)
  # Default keywords: ssn, email, phone, address, credit_card, password, etc.
  custom_pii_keywords:
    - "employee_id"
    - "customer_number"
    - "internal_code"
    - "confidential"

# Quality Checks Configuration
# ----------------------------------------------------------------------------
# Enable/disable specific checks
checks:
  # Check for leading/trailing whitespace
  trailing_spaces: true

  # Check for values that differ only in case (e.g., "JOHN" vs "john")
  case_duplicates: true

  # Check for special characters (emojis, accents, etc.)
  special_characters: true

  # Check for string columns containing only numbers
  numeric_strings: true

  # Check for timestamps that are effectively dates
  timestamp_patterns: true

  # Check for date/timestamp outliers (very old or future dates)
  date_outliers: true

  # Custom regex pattern for special characters
  # Default: [^a-zA-Z0-9\s\.,\-_@]
  special_chars_pattern: "[^a-zA-Z0-9\\s\\.,\\-_@]"

# Detection Thresholds (percentages)
# ----------------------------------------------------------------------------
thresholds:
  # Percentage of numeric values to flag a string column as "should be numeric"
  # Example: If 85% of values in a string column are numbers, flag it
  numeric_string_pct: 80

  # Percentage threshold for constant hour detection
  # Example: If 92% of timestamps have the same hour, flag as date-only
  constant_hour_pct: 90

  # Percentage threshold for midnight timestamps
  # Example: If 96% of timestamps are at midnight, suggest DATE type
  midnight_pct: 95

  # Date outlier detection thresholds
  # Minimum reasonable year (dates before this are flagged)
  min_year: 1950

  # Maximum reasonable year (dates after this are flagged)
  max_year: 2100

  # Minimum percentage to report as outlier (default: 0.01 = 1%)
  # Only report if at least this % of rows have outliers
  outlier_threshold_pct: 0.01

# Output Configuration
# ----------------------------------------------------------------------------
output:
  # Directory where audit results will be saved
  directory: "audit_results"
  
  # Export formats: html, json, csv, parquet
  formats:
    - html      # Beautiful interactive report
    - csv       # For Excel/analysis
    - json      # For APIs/automation
  
  # Prefix for output filenames
  # Final format: {prefix}_{table_name}_{timestamp}.{extension}
  file_prefix: "audit"

# Column Filters (Optional)
# ----------------------------------------------------------------------------
# Use these to limit which columns are audited
filters:
  # If specified, ONLY audit these columns (leave empty to audit all)
  include_columns: []
    # - "customer_name"
    # - "email"
    # - "created_at"
  
  # If specified, SKIP these columns
  exclude_columns: []
    # - "internal_metadata"
    # - "system_field"
    # - "deprecated_column"


# ============================================================================
# Example Configurations for Different Scenarios
# ============================================================================

# --- Example 1: Minimal Configuration ---
# database:
#   connection_string: "postgresql://user:pass@localhost/db"
# tables:
#   - users
#   - orders
# output:
#   directory: "audit_results"
#   formats: [html]

# --- Example 2: High-Security Configuration ---
# database:
#   connection_string: "postgresql://user:pass@localhost/db"
# tables:
#   - sensitive_data
# security:
#   mask_pii: true
#   custom_pii_keywords:
#     - "proprietary"
#     - "confidential"
#     - "restricted"
# sampling:
#   sample_in_db: true
#   sample_size: 10000
# output:
#   directory: "secure_audits"
#   formats: [html, json]

# --- Example 3: Production Data Warehouse ---
# database:
#   connection_string: "postgresql://readonly:pass@prod-warehouse/analytics"
#   schema: "public"
# tables:
#   - fact_sales
#   - fact_orders
#   - dim_customers
#   - dim_products
#   - dim_time
# sampling:
#   sample_size: 500000
#   sample_threshold: 5000000
#   sample_in_db: true
# security:
#   mask_pii: true
# output:
#   directory: "/shared/audit_reports"
#   formats: [html, csv, parquet]
#   file_prefix: "prod_audit"

# --- Example 4: Quick Development Audit ---
# database:
#   connection_string: "sqlite:///local.db"
# tables:
#   - test_table
# checks:
#   trailing_spaces: true
#   case_duplicates: true
#   special_characters: false
#   numeric_strings: false
#   timestamp_patterns: false
# sampling:
#   sample_threshold: 10000
# output:
#   directory: "quick_audit"
#   formats: [html]

# --- Example 5: Specific Columns Only ---
# database:
#   connection_string: "postgresql://user:pass@localhost/db"
# tables:
#   - customer_data
# filters:
#   include_columns:
#     - "email"
#     - "phone"
#     - "address"
#     - "name"
# output:
#   directory: "column_audit"
#   formats: [csv]

# --- Example 6: Exclude System Columns ---
# database:
#   connection_string: "postgresql://user:pass@localhost/db"
# tables:
#   - application_logs
# filters:
#   exclude_columns:
#     - "id"
#     - "created_at"
#     - "updated_at"
#     - "deleted_at"
#     - "version"
# output:
#   formats: [html]

# --- Example 7: Custom Thresholds ---
# database:
#   connection_string: "postgresql://user:pass@localhost/db"
# tables:
#   - legacy_data
# thresholds:
#   numeric_string_pct: 95  # Very strict
#   constant_hour_pct: 99   # Very strict
#   midnight_pct: 99        # Very strict
# output:
#   formats: [html, csv]

# --- Example 8: Multiple Tables with Custom Queries ---
# database:
#   connection_string: "postgresql://user:pass@localhost/analytics"
#   schema: "public"
# tables:
#   - name: recent_sales
#     query: "SELECT * FROM sales WHERE sale_date >= CURRENT_DATE - INTERVAL '7 days'"
#   - name: active_customers
#     query: "SELECT * FROM customers WHERE last_login > CURRENT_DATE - INTERVAL '30 days'"
#   - name: high_value_orders
#     query: "SELECT * FROM orders WHERE total_amount > 1000"
# security:
#   mask_pii: true
# output:
#   directory: "filtered_audits"
#   formats: [html, csv, json]
#   file_prefix: "filtered"