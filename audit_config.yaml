# Data Warehouse Audit Configuration
# ============================================================================
# Quick start configuration - Edit the values below with your database details
# For full documentation, see: https://github.com/your-repo/database_audit

# Database Connection
# ----------------------------------------------------------------------------
database:
  backend: "snowflake"  # Options: bigquery, snowflake
  connection_params:
    # Required for all backends
    default_database: "MY_DATABASE"  # BigQuery: project_id | Snowflake: DATABASE
    default_schema: "MY_SCHEMA"      # BigQuery: dataset | Snowflake: SCHEMA

    # ==================================================
    # SNOWFLAKE CONNECTION (recommended: use environment variables)
    # ==================================================
    # Create a .env file in this directory with:
    #   SNOWFLAKE_ACCOUNT="your-account"
    #   SNOWFLAKE_USER="your-username"
    #   SNOWFLAKE_PASSWORD="your-password"
    #
    # Then reference them here (keeps credentials out of version control):
    account: "${SNOWFLAKE_ACCOUNT}"
    user: "${SNOWFLAKE_USER}"
    password: "${SNOWFLAKE_PASSWORD}"
    # warehouse: "${SNOWFLAKE_WAREHOUSE:-COMPUTE_WH}"  # Optional, with default value
    # role: "${SNOWFLAKE_ROLE}"                        # Optional

    # ==================================================
    # BIGQUERY CONNECTION
    # ==================================================
    # Uncomment and configure if using BigQuery:
    # backend: "bigquery"
    # default_database: "your-project-id"
    # default_schema: "your-dataset"
    # credentials_path: "/path/to/service-account.json"  # Optional
    # If credentials_path not specified, uses: gcloud auth application-default login

# Tables to Audit
# ----------------------------------------------------------------------------
# List specific tables or leave empty to discover all tables automatically
tables:
  # Examples:
  # - customers
  # - orders
  #
  # Cross-schema/database tables:
  # - name: dim_users
  #   schema: analytics
  #
  # - name: events
  #   database: other-project
  #   schema: raw_data

# Sampling (optional)
# ----------------------------------------------------------------------------
# For large tables (>100k rows), sample data for faster audits
sampling:
  sample_size: 10000  # Number of rows to analyze from large tables

# Output Configuration
# ----------------------------------------------------------------------------
output:
  directory: "audit_results"
  formats: [html, json, csv]  # Choose: html, json, csv
  auto_open_html: false # Opens HTML reports in browser when audit ends

  # Number formatting (optional)
  number_format:
    thousand_separator: ","
    decimal_places: 1

# Quality Checks (optional)
# ----------------------------------------------------------------------------
# Enable/disable specific data quality checks
column_checks:
  defaults:
    string:
      trailing_characters: true   # Detect trailing whitespace
      case_duplicates: true        # Find duplicates ignoring case
    datetime:
      future_dates: true           # Detect dates in the future
      date_outliers:               # Detect suspicious placeholder years
        min_year: 1950
        max_year: 2100

# Column Insights (optional)
# ----------------------------------------------------------------------------
# Profile data distributions and statistics
column_insights:
  defaults:
    numeric:
      quantiles: true  # Calculate percentiles
    string:
      top_values:      # Show most frequent values
        limit: 10
